{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea461017-aba5-4490-8f83-6e1f66cda298",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import RGCNConv\n",
    "from torch_geometric.utils import negative_sampling\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dda39116-e43e-4342-af65-0a7170ec15f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_actions = pd.read_csv(\"df_actions_148k.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c87ce81c-9820-466a-9837-38fdb4433b1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence_a</th>\n",
       "      <th>sequence_b</th>\n",
       "      <th>item_id_a</th>\n",
       "      <th>item_id_b</th>\n",
       "      <th>mode</th>\n",
       "      <th>is_directional</th>\n",
       "      <th>a_is_acting</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MGLTVSALFSRIFGKKQMRILMVGLDAAGKTTILYKLKLGEIVTTI...</td>\n",
       "      <td>MAAAAAQGGGGGEPRRTEGVGPGVPGEVEMVKGQPFDVGPRYTQLQ...</td>\n",
       "      <td>9606.ENSP00000000233</td>\n",
       "      <td>9606.ENSP00000263025</td>\n",
       "      <td>ptmod</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MGLTVSALFSRIFGKKQMRILMVGLDAAGKTTILYKLKLGEIVTTI...</td>\n",
       "      <td>MAQAAKQLKKIKDIEAQALQEQKEKEESNRKRRNRSRDRKKKADAA...</td>\n",
       "      <td>9606.ENSP00000000233</td>\n",
       "      <td>9606.ENSP00000265709</td>\n",
       "      <td>reaction</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MGLTVSALFSRIFGKKQMRILMVGLDAAGKTTILYKLKLGEIVTTI...</td>\n",
       "      <td>MAQAAKQLKKIKDIEAQALQEQKEKEESNRKRRNRSRDRKKKADAA...</td>\n",
       "      <td>9606.ENSP00000000233</td>\n",
       "      <td>9606.ENSP00000265709</td>\n",
       "      <td>catalysis</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MGLTVSALFSRIFGKKQMRILMVGLDAAGKTTILYKLKLGEIVTTI...</td>\n",
       "      <td>MAAAAAQGGGGGEPRRTEGVGPGVPGEVEMVKGQPFDVGPRYTQLQ...</td>\n",
       "      <td>9606.ENSP00000000233</td>\n",
       "      <td>9606.ENSP00000263025</td>\n",
       "      <td>inhibition</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MGLTVSALFSRIFGKKQMRILMVGLDAAGKTTILYKLKLGEIVTTI...</td>\n",
       "      <td>MAQAAKQLKKIKDIEAQALQEQKEKEESNRKRRNRSRDRKKKADAA...</td>\n",
       "      <td>9606.ENSP00000000233</td>\n",
       "      <td>9606.ENSP00000265709</td>\n",
       "      <td>binding</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>908</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          sequence_a  \\\n",
       "0  MGLTVSALFSRIFGKKQMRILMVGLDAAGKTTILYKLKLGEIVTTI...   \n",
       "1  MGLTVSALFSRIFGKKQMRILMVGLDAAGKTTILYKLKLGEIVTTI...   \n",
       "2  MGLTVSALFSRIFGKKQMRILMVGLDAAGKTTILYKLKLGEIVTTI...   \n",
       "3  MGLTVSALFSRIFGKKQMRILMVGLDAAGKTTILYKLKLGEIVTTI...   \n",
       "4  MGLTVSALFSRIFGKKQMRILMVGLDAAGKTTILYKLKLGEIVTTI...   \n",
       "\n",
       "                                          sequence_b             item_id_a  \\\n",
       "0  MAAAAAQGGGGGEPRRTEGVGPGVPGEVEMVKGQPFDVGPRYTQLQ...  9606.ENSP00000000233   \n",
       "1  MAQAAKQLKKIKDIEAQALQEQKEKEESNRKRRNRSRDRKKKADAA...  9606.ENSP00000000233   \n",
       "2  MAQAAKQLKKIKDIEAQALQEQKEKEESNRKRRNRSRDRKKKADAA...  9606.ENSP00000000233   \n",
       "3  MAAAAAQGGGGGEPRRTEGVGPGVPGEVEMVKGQPFDVGPRYTQLQ...  9606.ENSP00000000233   \n",
       "4  MAQAAKQLKKIKDIEAQALQEQKEKEESNRKRRNRSRDRKKKADAA...  9606.ENSP00000000233   \n",
       "\n",
       "              item_id_b        mode is_directional a_is_acting  score  \n",
       "0  9606.ENSP00000263025       ptmod              f           f    150  \n",
       "1  9606.ENSP00000265709    reaction              f           f    908  \n",
       "2  9606.ENSP00000265709   catalysis              t           t    908  \n",
       "3  9606.ENSP00000263025  inhibition              t           t    154  \n",
       "4  9606.ENSP00000265709     binding              f           t    908  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_actions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "105cf3dd-48aa-4db1-895a-ab2b03c97ab0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Total edge types (relations): 20\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Create a mapping from protein IDs to indices\n",
    "protein_ids = pd.concat([df_actions['item_id_a'], df_actions['item_id_b']]).unique()\n",
    "protein_to_idx = {protein: idx for idx, protein in enumerate(protein_ids)}\n",
    "\n",
    "# Step 2: Map interaction mode to integers\n",
    "mode_to_int = {mode: i for i, mode in enumerate(df_actions['mode'].unique())}\n",
    "df_actions['edge_type'] = df_actions['mode'].map(mode_to_int)\n",
    "\n",
    "# Step 3: Create edge index and edge type\n",
    "# Step 3: Direction-aware multi-relation edge construction\n",
    "src_nodes = []\n",
    "dst_nodes = []\n",
    "edge_types = []\n",
    "\n",
    "# Combine interaction type and direction into edge_type\n",
    "# Example: \"activation_forward\", \"activation_reverse\", \"activation_bidirectional\"\n",
    "relation_to_id = {}\n",
    "relation_counter = 0\n",
    "\n",
    "for _, row in df_actions.iterrows():\n",
    "    a = row[\"item_id_a\"]\n",
    "    b = row[\"item_id_b\"]\n",
    "    mode = row[\"mode\"]\n",
    "    is_dir = row[\"is_directional\"]\n",
    "    a_acts = row[\"a_is_acting\"]\n",
    "\n",
    "    if is_dir == \"t\":\n",
    "        if a_acts == \"t\":\n",
    "            src = protein_to_idx[a]\n",
    "            dst = protein_to_idx[b]\n",
    "            rel = f\"{mode}_forward\"\n",
    "        else:\n",
    "            src = protein_to_idx[b]\n",
    "            dst = protein_to_idx[a]\n",
    "            rel = f\"{mode}_reverse\"\n",
    "\n",
    "        if rel not in relation_to_id:\n",
    "            relation_to_id[rel] = relation_counter\n",
    "            relation_counter += 1\n",
    "\n",
    "        src_nodes.append(src)\n",
    "        dst_nodes.append(dst)\n",
    "        edge_types.append(relation_to_id[rel])\n",
    "\n",
    "    else:\n",
    "        # Undirected: add both directions as \"_bidirectional\"\n",
    "        rel = f\"{mode}_bidirectional\"\n",
    "        if rel not in relation_to_id:\n",
    "            relation_to_id[rel] = relation_counter\n",
    "            relation_counter += 1\n",
    "\n",
    "        src_nodes.append(protein_to_idx[a])\n",
    "        dst_nodes.append(protein_to_idx[b])\n",
    "        edge_types.append(relation_to_id[rel])\n",
    "\n",
    "        src_nodes.append(protein_to_idx[b])\n",
    "        dst_nodes.append(protein_to_idx[a])\n",
    "        edge_types.append(relation_to_id[rel])\n",
    "\n",
    "edge_index = torch.tensor([src_nodes, dst_nodes], dtype=torch.long)\n",
    "edge_type = torch.tensor(edge_types, dtype=torch.long)\n",
    "\n",
    "print(f\"✅ Total edge types (relations): {len(relation_to_id)}\")\n",
    "\n",
    "# Step 4: Create node features (one-hot encoding of sequences)\n",
    "amino_acids = list(\"ACDEFGHIKLMNPQRSTVWXY\")\n",
    "encoder = OneHotEncoder(categories=[amino_acids], sparse_output=False)\n",
    "\n",
    "node_features = []\n",
    "for protein in protein_ids:\n",
    "    sequence_a = df_actions[df_actions['item_id_a'] == protein]['sequence_a']\n",
    "    sequence_b = df_actions[df_actions['item_id_b'] == protein]['sequence_b']\n",
    "    \n",
    "    if len(sequence_a) > 0:\n",
    "        sequence = sequence_a.values[0]\n",
    "    elif len(sequence_b) > 0:\n",
    "        sequence = sequence_b.values[0]\n",
    "    else:\n",
    "        raise ValueError(f\"Protein {protein} not found in either 'item_id_a' or 'item_id_b'.\")\n",
    "    \n",
    "    encoded_seq = encoder.fit_transform(np.array(list(sequence)).reshape(-1, 1))\n",
    "    node_features.append(encoded_seq.mean(axis=0))\n",
    "\n",
    "node_features_array = np.array(node_features)\n",
    "\n",
    "# Step 5: Create PyG Data object\n",
    "data = Data(\n",
    "    x=torch.tensor(node_features_array, dtype=torch.float),  # Node features\n",
    "    edge_index=edge_index,  # Edge indices\n",
    "    edge_type=edge_type  # Edge types\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed5b07f8-3587-44ca-9489-611410a50f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map interaction mode to integers\n",
    "mode_to_int = {mode: i for i, mode in enumerate(df_actions['mode'].unique())}\n",
    "df_actions['edge_type'] = df_actions['mode'].map(mode_to_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe5d36d7-67ed-4eb3-894b-0d2a7116f9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Step 1: Create a mapping from protein IDs to indices\n",
    "# protein_ids = pd.concat([df_actions['item_id_a'], df_actions['item_id_b']]).unique()\n",
    "# protein_to_idx = {protein: idx for idx, protein in enumerate(protein_ids)}\n",
    "\n",
    "# # Step 2: Map interaction mode to integers\n",
    "# mode_to_int = {mode: i for i, mode in enumerate(df_actions['mode'].unique())}\n",
    "# df_actions['edge_type'] = df_actions['mode'].map(mode_to_int)\n",
    "\n",
    "# # Step 3: Create edge index and edge type\n",
    "# edge_index = torch.tensor([\n",
    "#     [protein_to_idx[protein] for protein in df_actions['item_id_a']],\n",
    "#     [protein_to_idx[protein] for protein in df_actions['item_id_b']]\n",
    "# ], dtype=torch.long)\n",
    "\n",
    "# edge_type = torch.tensor(df_actions['edge_type'].values, dtype=torch.long)\n",
    "\n",
    "# # Step 4: Create node features (one-hot encoding of sequences)\n",
    "# amino_acids = list(\"ACDEFGHIKLMNPQRSTVWY\")\n",
    "# encoder = OneHotEncoder(categories=[amino_acids], sparse_output=False)\n",
    "\n",
    "# node_features = []\n",
    "# for protein in protein_ids:\n",
    "#     sequence_a = df_actions[df_actions['item_id_a'] == protein]['sequence_a']\n",
    "#     sequence_b = df_actions[df_actions['item_id_b'] == protein]['sequence_b']\n",
    "    \n",
    "#     if len(sequence_a) > 0:\n",
    "#         sequence = sequence_a.values[0]\n",
    "#     elif len(sequence_b) > 0:\n",
    "#         sequence = sequence_b.values[0]\n",
    "#     else:\n",
    "#         raise ValueError(f\"Protein {protein} not found in either 'item_id_a' or 'item_id_b'.\")\n",
    "    \n",
    "#     encoded_seq = encoder.fit_transform(np.array(list(sequence)).reshape(-1, 1))\n",
    "#     node_features.append(encoded_seq.mean(axis=0))\n",
    "\n",
    "# node_features_array = np.array(node_features)\n",
    "\n",
    "# # Step 5: Create PyG Data object\n",
    "# data = Data(\n",
    "#     x=torch.tensor(node_features_array, dtype=torch.float),  # Node features\n",
    "#     edge_index=edge_index,  # Edge indices\n",
    "#     edge_type=edge_type  # Edge types\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ff1b0cb8-4255-432b-bacc-659aa1ba13ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RGCNLinkPrediction(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, num_relations):\n",
    "        super(RGCNLinkPrediction, self).__init__()\n",
    "        self.conv1 = RGCNConv(in_channels, hidden_channels, num_relations)\n",
    "        self.conv2 = RGCNConv(hidden_channels, out_channels, num_relations)\n",
    "\n",
    "    def encode(self, x, edge_index, edge_type):\n",
    "        x = self.conv1(x, edge_index, edge_type)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index, edge_type)\n",
    "        return x\n",
    "\n",
    "    def decode(self, z, edge_index):\n",
    "        return (z[edge_index[0]] * z[edge_index[1]]).sum(dim=-1)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_type):\n",
    "        z = self.encode(x, edge_index, edge_type)\n",
    "        return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "18a4032f-064c-44e5-9abc-d7e85244a892",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 1.1125\n",
      "Epoch: 002, Loss: 1.2081\n",
      "Epoch: 003, Loss: 1.0382\n",
      "Epoch: 004, Loss: 1.0505\n",
      "Epoch: 005, Loss: 1.0719\n",
      "Epoch: 006, Loss: 1.0506\n",
      "Epoch: 007, Loss: 1.0165\n",
      "Epoch: 008, Loss: 1.0061\n",
      "Epoch: 009, Loss: 1.0167\n",
      "Epoch: 010, Loss: 1.0143\n",
      "Epoch: 011, Loss: 0.9954\n",
      "Epoch: 012, Loss: 0.9790\n",
      "Epoch: 013, Loss: 0.9752\n",
      "Epoch: 014, Loss: 0.9780\n",
      "Epoch: 015, Loss: 0.9779\n",
      "Epoch: 016, Loss: 0.9719\n",
      "Epoch: 017, Loss: 0.9641\n",
      "Epoch: 018, Loss: 0.9600\n",
      "Epoch: 019, Loss: 0.9602\n",
      "Epoch: 020, Loss: 0.9593\n",
      "Epoch: 021, Loss: 0.9541\n",
      "Epoch: 022, Loss: 0.9478\n",
      "Epoch: 023, Loss: 0.9449\n",
      "Epoch: 024, Loss: 0.9456\n",
      "Epoch: 025, Loss: 0.9456\n",
      "Epoch: 026, Loss: 0.9428\n",
      "Epoch: 027, Loss: 0.9396\n",
      "Epoch: 028, Loss: 0.9384\n",
      "Epoch: 029, Loss: 0.9377\n",
      "Epoch: 030, Loss: 0.9365\n",
      "Epoch: 031, Loss: 0.9347\n",
      "Epoch: 032, Loss: 0.9322\n",
      "Epoch: 033, Loss: 0.9308\n",
      "Epoch: 034, Loss: 0.9307\n",
      "Epoch: 035, Loss: 0.9293\n",
      "Epoch: 036, Loss: 0.9273\n",
      "Epoch: 037, Loss: 0.9257\n",
      "Epoch: 038, Loss: 0.9246\n",
      "Epoch: 039, Loss: 0.9239\n",
      "Epoch: 040, Loss: 0.9226\n",
      "Epoch: 041, Loss: 0.9210\n",
      "Epoch: 042, Loss: 0.9202\n",
      "Epoch: 043, Loss: 0.9196\n",
      "Epoch: 044, Loss: 0.9184\n",
      "Epoch: 045, Loss: 0.9173\n",
      "Epoch: 046, Loss: 0.9161\n",
      "Epoch: 047, Loss: 0.9155\n",
      "Epoch: 048, Loss: 0.9148\n",
      "Epoch: 049, Loss: 0.9138\n",
      "Epoch: 050, Loss: 0.9132\n",
      "Epoch: 051, Loss: 0.9126\n",
      "Epoch: 052, Loss: 0.9119\n",
      "Epoch: 053, Loss: 0.9111\n",
      "Epoch: 054, Loss: 0.9103\n",
      "Epoch: 055, Loss: 0.9098\n",
      "Epoch: 056, Loss: 0.9091\n",
      "Epoch: 057, Loss: 0.9084\n",
      "Epoch: 058, Loss: 0.9077\n",
      "Epoch: 059, Loss: 0.9071\n",
      "Epoch: 060, Loss: 0.9065\n",
      "Epoch: 061, Loss: 0.9057\n",
      "Epoch: 062, Loss: 0.9052\n",
      "Epoch: 063, Loss: 0.9046\n",
      "Epoch: 064, Loss: 0.9039\n",
      "Epoch: 065, Loss: 0.9032\n",
      "Epoch: 066, Loss: 0.9026\n",
      "Epoch: 067, Loss: 0.9020\n",
      "Epoch: 068, Loss: 0.9013\n",
      "Epoch: 069, Loss: 0.9007\n",
      "Epoch: 070, Loss: 0.9001\n",
      "Epoch: 071, Loss: 0.8994\n",
      "Epoch: 072, Loss: 0.8988\n",
      "Epoch: 073, Loss: 0.8982\n",
      "Epoch: 074, Loss: 0.8976\n",
      "Epoch: 075, Loss: 0.8970\n",
      "Epoch: 076, Loss: 0.8964\n",
      "Epoch: 077, Loss: 0.8958\n",
      "Epoch: 078, Loss: 0.8951\n",
      "Epoch: 079, Loss: 0.8945\n",
      "Epoch: 080, Loss: 0.8939\n",
      "Epoch: 081, Loss: 0.8934\n",
      "Epoch: 082, Loss: 0.8928\n",
      "Epoch: 083, Loss: 0.8922\n",
      "Epoch: 084, Loss: 0.8916\n",
      "Epoch: 085, Loss: 0.8910\n",
      "Epoch: 086, Loss: 0.8904\n",
      "Epoch: 087, Loss: 0.8898\n",
      "Epoch: 088, Loss: 0.8892\n",
      "Epoch: 089, Loss: 0.8887\n",
      "Epoch: 090, Loss: 0.8881\n",
      "Epoch: 091, Loss: 0.8875\n",
      "Epoch: 092, Loss: 0.8869\n",
      "Epoch: 093, Loss: 0.8863\n",
      "Epoch: 094, Loss: 0.8857\n",
      "Epoch: 095, Loss: 0.8851\n",
      "Epoch: 096, Loss: 0.8845\n",
      "Epoch: 097, Loss: 0.8839\n",
      "Epoch: 098, Loss: 0.8833\n",
      "Epoch: 099, Loss: 0.8827\n",
      "Epoch: 100, Loss: 0.8821\n",
      "Epoch: 101, Loss: 0.8815\n",
      "Epoch: 102, Loss: 0.8809\n",
      "Epoch: 103, Loss: 0.8803\n",
      "Epoch: 104, Loss: 0.8797\n",
      "Epoch: 105, Loss: 0.8790\n",
      "Epoch: 106, Loss: 0.8784\n",
      "Epoch: 107, Loss: 0.8778\n",
      "Epoch: 108, Loss: 0.8772\n",
      "Epoch: 109, Loss: 0.8766\n",
      "Epoch: 110, Loss: 0.8760\n",
      "Epoch: 111, Loss: 0.8754\n",
      "Epoch: 112, Loss: 0.8747\n",
      "Epoch: 113, Loss: 0.8741\n",
      "Epoch: 114, Loss: 0.8735\n",
      "Epoch: 115, Loss: 0.8729\n",
      "Epoch: 116, Loss: 0.8722\n",
      "Epoch: 117, Loss: 0.8717\n",
      "Epoch: 118, Loss: 0.8711\n",
      "Epoch: 119, Loss: 0.8706\n",
      "Epoch: 120, Loss: 0.8700\n",
      "Epoch: 121, Loss: 0.8695\n",
      "Epoch: 122, Loss: 0.8691\n",
      "Epoch: 123, Loss: 0.8692\n",
      "Epoch: 124, Loss: 0.8687\n",
      "Epoch: 125, Loss: 0.8676\n",
      "Epoch: 126, Loss: 0.8664\n",
      "Epoch: 127, Loss: 0.8664\n",
      "Epoch: 128, Loss: 0.8663\n",
      "Epoch: 129, Loss: 0.8655\n",
      "Epoch: 130, Loss: 0.8648\n",
      "Epoch: 131, Loss: 0.8640\n",
      "Epoch: 132, Loss: 0.8642\n",
      "Epoch: 133, Loss: 0.8635\n",
      "Epoch: 134, Loss: 0.8626\n",
      "Epoch: 135, Loss: 0.8625\n",
      "Epoch: 136, Loss: 0.8619\n",
      "Epoch: 137, Loss: 0.8615\n",
      "Epoch: 138, Loss: 0.8608\n",
      "Epoch: 139, Loss: 0.8604\n",
      "Epoch: 140, Loss: 0.8602\n",
      "Epoch: 141, Loss: 0.8594\n",
      "Epoch: 142, Loss: 0.8591\n",
      "Epoch: 143, Loss: 0.8588\n",
      "Epoch: 144, Loss: 0.8582\n",
      "Epoch: 145, Loss: 0.8579\n",
      "Epoch: 146, Loss: 0.8574\n",
      "Epoch: 147, Loss: 0.8569\n",
      "Epoch: 148, Loss: 0.8566\n",
      "Epoch: 149, Loss: 0.8563\n",
      "Epoch: 150, Loss: 0.8557\n",
      "Epoch: 151, Loss: 0.8555\n",
      "Epoch: 152, Loss: 0.8552\n",
      "Epoch: 153, Loss: 0.8546\n",
      "Epoch: 154, Loss: 0.8544\n",
      "Epoch: 155, Loss: 0.8541\n",
      "Epoch: 156, Loss: 0.8535\n",
      "Epoch: 157, Loss: 0.8531\n",
      "Epoch: 158, Loss: 0.8529\n",
      "Epoch: 159, Loss: 0.8526\n",
      "Epoch: 160, Loss: 0.8521\n",
      "Epoch: 161, Loss: 0.8519\n",
      "Epoch: 162, Loss: 0.8517\n",
      "Epoch: 163, Loss: 0.8516\n",
      "Epoch: 164, Loss: 0.8515\n",
      "Epoch: 165, Loss: 0.8518\n",
      "Epoch: 166, Loss: 0.8519\n",
      "Epoch: 167, Loss: 0.8513\n",
      "Epoch: 168, Loss: 0.8499\n",
      "Epoch: 169, Loss: 0.8493\n",
      "Epoch: 170, Loss: 0.8496\n",
      "Epoch: 171, Loss: 0.8495\n",
      "Epoch: 172, Loss: 0.8490\n",
      "Epoch: 173, Loss: 0.8481\n",
      "Epoch: 174, Loss: 0.8481\n",
      "Epoch: 175, Loss: 0.8482\n",
      "Epoch: 176, Loss: 0.8478\n",
      "Epoch: 177, Loss: 0.8471\n",
      "Epoch: 178, Loss: 0.8468\n",
      "Epoch: 179, Loss: 0.8468\n",
      "Epoch: 180, Loss: 0.8467\n",
      "Epoch: 181, Loss: 0.8461\n",
      "Epoch: 182, Loss: 0.8456\n",
      "Epoch: 183, Loss: 0.8455\n",
      "Epoch: 184, Loss: 0.8454\n",
      "Epoch: 185, Loss: 0.8451\n",
      "Epoch: 186, Loss: 0.8447\n",
      "Epoch: 187, Loss: 0.8444\n",
      "Epoch: 188, Loss: 0.8443\n",
      "Epoch: 189, Loss: 0.8441\n",
      "Epoch: 190, Loss: 0.8438\n",
      "Epoch: 191, Loss: 0.8435\n",
      "Epoch: 192, Loss: 0.8433\n",
      "Epoch: 193, Loss: 0.8430\n",
      "Epoch: 194, Loss: 0.8428\n",
      "Epoch: 195, Loss: 0.8426\n",
      "Epoch: 196, Loss: 0.8424\n",
      "Epoch: 197, Loss: 0.8422\n",
      "Epoch: 198, Loss: 0.8419\n",
      "Epoch: 199, Loss: 0.8416\n",
      "Epoch: 200, Loss: 0.8414\n",
      "Validation AUC-ROC: 0.8351, Validation AUC-PR: 0.8870\n",
      "Test AUC-ROC: 0.9113, Test AUC-PR: 0.9344\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Split edge_index and edge_type\n",
    "edge_index = data.edge_index.numpy()\n",
    "edge_type = data.edge_type.numpy()\n",
    "\n",
    "# Split edge_index and edge_type into training, validation, and test sets\n",
    "edge_index_train, edge_index_test, edge_type_train, edge_type_test = train_test_split(\n",
    "    edge_index.T, edge_type, test_size=0.2, random_state=42\n",
    ")\n",
    "edge_index_train, edge_index_val, edge_type_train, edge_type_val = train_test_split(\n",
    "    edge_index_train, edge_type_train, test_size=0.1, random_state=42\n",
    ")\n",
    "\n",
    "# Convert back to tensors\n",
    "edge_index_train = torch.tensor(edge_index_train, dtype=torch.long).t()\n",
    "edge_index_val = torch.tensor(edge_index_val, dtype=torch.long).t()\n",
    "edge_index_test = torch.tensor(edge_index_test, dtype=torch.long).t()\n",
    "\n",
    "edge_type_train = torch.tensor(edge_type_train, dtype=torch.long)\n",
    "edge_type_val = torch.tensor(edge_type_val, dtype=torch.long)\n",
    "edge_type_test = torch.tensor(edge_type_test, dtype=torch.long)\n",
    "\n",
    "# Step 2: Generate negative samples\n",
    "neg_edge_index_train = negative_sampling(edge_index_train, num_nodes=data.num_nodes)\n",
    "neg_edge_index_val = negative_sampling(edge_index_val, num_nodes=data.num_nodes)\n",
    "neg_edge_index_test = negative_sampling(edge_index_test, num_nodes=data.num_nodes)\n",
    "\n",
    "# Step 3: Initialize the model\n",
    "model = RGCNLinkPrediction(\n",
    "    in_channels=data.num_features,\n",
    "    hidden_channels=16,\n",
    "    out_channels=16,\n",
    "    num_relations=len(relation_to_id)  # Number of interaction modes\n",
    ")\n",
    "\n",
    "# Step 4: Optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# Step 5: Training loop\n",
    "def train():\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    pos_edge_index = edge_index_train\n",
    "    neg_edge_index = neg_edge_index_train\n",
    "    \n",
    "    # Pass edge_type_train to the model\n",
    "    z = model(data.x, pos_edge_index, edge_type_train)\n",
    "    pos_score = model.decode(z, pos_edge_index)\n",
    "    neg_score = model.decode(z, neg_edge_index)\n",
    "    \n",
    "    pos_loss = F.binary_cross_entropy_with_logits(pos_score, torch.ones(pos_score.size(0)))\n",
    "    neg_loss = F.binary_cross_entropy_with_logits(neg_score, torch.zeros(neg_score.size(0)))\n",
    "    loss = pos_loss + neg_loss\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    return loss.item()\n",
    "\n",
    "for epoch in range(1, 201):\n",
    "    loss = train()\n",
    "    print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}')\n",
    "\n",
    "# Step 6: Evaluate the model\n",
    "def evaluate(edge_index, edge_type, neg_edge_index):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        z = model(data.x, edge_index, edge_type)\n",
    "        pos_score = model.decode(z, edge_index).sigmoid().cpu().numpy()\n",
    "        neg_score = model.decode(z, neg_edge_index).sigmoid().cpu().numpy()\n",
    "        \n",
    "        y_true = np.hstack([np.ones(pos_score.size), np.zeros(neg_score.size)])\n",
    "        y_score = np.hstack([pos_score, neg_score])\n",
    "        \n",
    "        auc_roc = roc_auc_score(y_true, y_score)\n",
    "        auc_pr = average_precision_score(y_true, y_score)\n",
    "        \n",
    "        return auc_roc, auc_pr\n",
    "\n",
    "# Evaluate on validation set\n",
    "val_auc_roc, val_auc_pr = evaluate(edge_index_val, edge_type_val, neg_edge_index_val)\n",
    "print(f\"Validation AUC-ROC: {val_auc_roc:.4f}, Validation AUC-PR: {val_auc_pr:.4f}\")\n",
    "\n",
    "# Evaluate on test set\n",
    "test_auc_roc, test_auc_pr = evaluate(edge_index_test, edge_type_test, neg_edge_index_test)\n",
    "print(f\"Test AUC-ROC: {test_auc_roc:.4f}, Test AUC-PR: {test_auc_pr:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2fcb1111-db6e-4e93-875f-0c7bab43d435",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(edge_index, edge_type, neg_edge_index):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        z = model(data.x, edge_index, edge_type)\n",
    "        pos_score = model.decode(z, edge_index).sigmoid().cpu().numpy()\n",
    "        neg_score = model.decode(z, neg_edge_index).sigmoid().cpu().numpy()\n",
    "        \n",
    "        y_true = np.hstack([np.ones(pos_score.size), np.zeros(neg_score.size)])\n",
    "        y_score = np.hstack([pos_score, neg_score])\n",
    "        \n",
    "        auc_roc = roc_auc_score(y_true, y_score)\n",
    "        auc_pr = average_precision_score(y_true, y_score)\n",
    "        \n",
    "        return auc_roc, auc_pr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e366af41-bc90-4987-84df-0666d46634f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation AUC-ROC: 0.8351, Validation AUC-PR: 0.8870\n",
      "Test AUC-ROC: 0.9113, Test AUC-PR: 0.9344\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on validation set\n",
    "val_auc_roc, val_auc_pr = evaluate(edge_index_val, edge_type_val, neg_edge_index_val)\n",
    "print(f\"Validation AUC-ROC: {val_auc_roc:.4f}, Validation AUC-PR: {val_auc_pr:.4f}\")\n",
    "\n",
    "# Evaluate on test set\n",
    "test_auc_roc, test_auc_pr = evaluate(edge_index_test, edge_type_test, neg_edge_index_test)\n",
    "print(f\"Test AUC-ROC: {test_auc_roc:.4f}, Test AUC-PR: {test_auc_pr:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c0be6c-cfd2-4e76-b868-7747c456d18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "z = model.encode(data.x, data.edge_index, data.edge_type).detach().cpu().numpy()\n",
    "tsne = TSNE(n_components=2, random_state=42)\n",
    "z_2d = tsne.fit_transform(z)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.scatter(z_2d[:, 0], z_2d[:, 1], s=10)\n",
    "plt.title(\"t-SNE Visualization of Node Embeddings\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eba37ed-c554-4e0d-8d32-94f2763e757d",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"rgcn_link_prediction_model_148k_directional.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a89dd99-5c35-4d50-a2f0-a88e0e8e3f21",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
