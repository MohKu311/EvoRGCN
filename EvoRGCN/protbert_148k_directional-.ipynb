{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f06ccca2-2732-4c8c-ace5-fc148ba0f566",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import RGCNConv\n",
    "from torch_geometric.utils import negative_sampling\n",
    "from transformers import BertModel, BertTokenizer\n",
    "from tqdm import tqdm\n",
    "import pickle, os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4351f2b1-f09f-4961-a90f-b1b4c1fc8a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "# -----------------------------\n",
    "df = pd.read_csv(\"df_actions_27k.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6319c4d-cd9b-49c7-89bd-09907bbba018",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence_a</th>\n",
       "      <th>sequence_b</th>\n",
       "      <th>item_id_a</th>\n",
       "      <th>item_id_b</th>\n",
       "      <th>mode</th>\n",
       "      <th>is_directional</th>\n",
       "      <th>a_is_acting</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MGLTVSALFSRIFGKKQMRILMVGLDAAGKTTILYKLKLGEIVTTI...</td>\n",
       "      <td>MALWMRLLPLLALLALWGPDPAAAFVNQHLCGSHLVEALYLVCGER...</td>\n",
       "      <td>9606.ENSP00000000233</td>\n",
       "      <td>9606.ENSP00000250971</td>\n",
       "      <td>reaction</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MGLTVSALFSRIFGKKQMRILMVGLDAAGKTTILYKLKLGEIVTTI...</td>\n",
       "      <td>MALWMRLLPLLALLALWGPDPAAAFVNQHLCGSHLVEALYLVCGER...</td>\n",
       "      <td>9606.ENSP00000000233</td>\n",
       "      <td>9606.ENSP00000250971</td>\n",
       "      <td>reaction</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MGLTVSALFSRIFGKKQMRILMVGLDAAGKTTILYKLKLGEIVTTI...</td>\n",
       "      <td>MTECFLPPTSSPSEHRRVEHGSGLTRTPSSEEISPTKFPGLYRTGE...</td>\n",
       "      <td>9606.ENSP00000000233</td>\n",
       "      <td>9606.ENSP00000019317</td>\n",
       "      <td>activation</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MGLTVSALFSRIFGKKQMRILMVGLDAAGKTTILYKLKLGEIVTTI...</td>\n",
       "      <td>MQQAPQPYEFFSEENSPKWRGLLVSALRKVQEQVHPTLSANEESLY...</td>\n",
       "      <td>9606.ENSP00000000233</td>\n",
       "      <td>9606.ENSP00000216373</td>\n",
       "      <td>reaction</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MGLTVSALFSRIFGKKQMRILMVGLDAAGKTTILYKLKLGEIVTTI...</td>\n",
       "      <td>MAMAEGERTECAEPPRDEPPADGALKRAEELKTQANDYFKAKDYEN...</td>\n",
       "      <td>9606.ENSP00000000233</td>\n",
       "      <td>9606.ENSP00000012443</td>\n",
       "      <td>catalysis</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>155</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          sequence_a  \\\n",
       "0  MGLTVSALFSRIFGKKQMRILMVGLDAAGKTTILYKLKLGEIVTTI...   \n",
       "1  MGLTVSALFSRIFGKKQMRILMVGLDAAGKTTILYKLKLGEIVTTI...   \n",
       "2  MGLTVSALFSRIFGKKQMRILMVGLDAAGKTTILYKLKLGEIVTTI...   \n",
       "3  MGLTVSALFSRIFGKKQMRILMVGLDAAGKTTILYKLKLGEIVTTI...   \n",
       "4  MGLTVSALFSRIFGKKQMRILMVGLDAAGKTTILYKLKLGEIVTTI...   \n",
       "\n",
       "                                          sequence_b             item_id_a  \\\n",
       "0  MALWMRLLPLLALLALWGPDPAAAFVNQHLCGSHLVEALYLVCGER...  9606.ENSP00000000233   \n",
       "1  MALWMRLLPLLALLALWGPDPAAAFVNQHLCGSHLVEALYLVCGER...  9606.ENSP00000000233   \n",
       "2  MTECFLPPTSSPSEHRRVEHGSGLTRTPSSEEISPTKFPGLYRTGE...  9606.ENSP00000000233   \n",
       "3  MQQAPQPYEFFSEENSPKWRGLLVSALRKVQEQVHPTLSANEESLY...  9606.ENSP00000000233   \n",
       "4  MAMAEGERTECAEPPRDEPPADGALKRAEELKTQANDYFKAKDYEN...  9606.ENSP00000000233   \n",
       "\n",
       "              item_id_b        mode is_directional a_is_acting  score  \n",
       "0  9606.ENSP00000250971    reaction              t           t    900  \n",
       "1  9606.ENSP00000250971    reaction              t           f    900  \n",
       "2  9606.ENSP00000019317  activation              f           f    175  \n",
       "3  9606.ENSP00000216373    reaction              f           f    161  \n",
       "4  9606.ENSP00000012443   catalysis              t           f    155  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92527211-dd8b-435d-9127-a1bd83e070c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map interaction mode to integer (used as edge type)\n",
    "df['edge_type'] = pd.factorize(df['mode'])[0]\n",
    "mode_to_int = dict(zip(df['mode'], df['edge_type']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b2a34027-8ec0-4d70-a7b5-530b45bfc723",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create protein-to-sequence map\n",
    "# -----------------------------\n",
    "proteins_a = df[[\"item_id_a\", \"sequence_a\"]].rename(columns={\"item_id_a\": \"item_id\", \"sequence_a\": \"sequence\"})\n",
    "proteins_b = df[[\"item_id_b\", \"sequence_b\"]].rename(columns={\"item_id_b\": \"item_id\", \"sequence_b\": \"sequence\"})\n",
    "all_proteins = pd.concat([proteins_a, proteins_b]).drop_duplicates(\"item_id\").set_index(\"item_id\")\n",
    "protein_to_idx = {pid: i for i, pid in enumerate(all_proteins.index)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fd13119d-2fec-4aef-a95b-6e8ec1cee1f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mohit\\anaconda3\\Lib\\site-packages\\torch\\_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    }
   ],
   "source": [
    "# ProtBERT Embedding\n",
    "# -----------------------------\n",
    "tokenizer = BertTokenizer.from_pretrained(\"Rostlab/prot_bert\", do_lower_case=False)\n",
    "model = BertModel.from_pretrained(\"Rostlab/prot_bert\").eval()\n",
    "\n",
    "def embed_sequence(seq):\n",
    "    seq = seq.replace(\" \", \"\").upper()\n",
    "    seq = \" \".join(list(seq))\n",
    "    tokens = tokenizer(seq, return_tensors=\"pt\", truncation=True, padding=True, max_length=1024)\n",
    "    with torch.no_grad():\n",
    "        output = model(**tokens)\n",
    "    return output.last_hidden_state.mean(dim=1).squeeze().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ba7b50f-cf12-4001-8a62-04ace104975f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Embedding proteins: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1690/1690 [1:55:44<00:00,  4.11s/it]\n"
     ]
    }
   ],
   "source": [
    "# Embed protein sequences (cached)\n",
    "# -----------------------------\n",
    "cache_path = \"protbert_embeddings_linkprediction_148k.pkl\"\n",
    "if os.path.exists(cache_path):\n",
    "    with open(cache_path, \"rb\") as f:\n",
    "        protein_embeddings = pickle.load(f)\n",
    "else:\n",
    "    protein_embeddings = {}\n",
    "    for pid in tqdm(all_proteins.index, desc=\"Embedding proteins\"):\n",
    "        try:\n",
    "            protein_embeddings[pid] = embed_sequence(all_proteins.loc[pid, \"sequence\"])\n",
    "        except Exception as e:\n",
    "            print(f\"Error embedding {pid}: {e}\")\n",
    "    with open(cache_path, \"wb\") as f:\n",
    "        pickle.dump(protein_embeddings, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3330aa96-7b2e-4829-a5db-b7c58756271e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create feature matrix\n",
    "# -----------------------------\n",
    "embedding_dim = len(next(iter(protein_embeddings.values())))\n",
    "x = np.zeros((len(protein_to_idx), embedding_dim), dtype=np.float32)\n",
    "for pid, idx in protein_to_idx.items():\n",
    "    x[idx] = protein_embeddings[pid]\n",
    "x = torch.tensor(x, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "84f0177e-e1bd-4335-97a6-e60c3712ba9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Total unique edge types: 20\n"
     ]
    }
   ],
   "source": [
    "# Build edges and edge types\n",
    "# -----------------------------\n",
    "# Direction-aware edge construction\n",
    "src_nodes = []\n",
    "dst_nodes = []\n",
    "edge_types = []\n",
    "\n",
    "relation_to_id = {}\n",
    "rel_id_counter = 0\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    a = row[\"item_id_a\"]\n",
    "    b = row[\"item_id_b\"]\n",
    "    mode = row[\"mode\"]\n",
    "    is_dir = row[\"is_directional\"]\n",
    "    a_acts = row[\"a_is_acting\"]\n",
    "\n",
    "    if is_dir == \"t\":\n",
    "        if a_acts == \"t\":\n",
    "            src = protein_to_idx[a]\n",
    "            dst = protein_to_idx[b]\n",
    "            rel = f\"{mode}_forward\"\n",
    "        else:\n",
    "            src = protein_to_idx[b]\n",
    "            dst = protein_to_idx[a]\n",
    "            rel = f\"{mode}_reverse\"\n",
    "    else:\n",
    "        # undirected â†’ add both edges\n",
    "        rel = f\"{mode}_bidirectional\"\n",
    "        src_nodes.append(protein_to_idx[a])\n",
    "        dst_nodes.append(protein_to_idx[b])\n",
    "        if rel not in relation_to_id:\n",
    "            relation_to_id[rel] = rel_id_counter\n",
    "            rel_id_counter += 1\n",
    "        edge_types.append(relation_to_id[rel])\n",
    "\n",
    "        src_nodes.append(protein_to_idx[b])\n",
    "        dst_nodes.append(protein_to_idx[a])\n",
    "        edge_types.append(relation_to_id[rel])\n",
    "        continue  # skip to next row\n",
    "\n",
    "    if rel not in relation_to_id:\n",
    "        relation_to_id[rel] = rel_id_counter\n",
    "        rel_id_counter += 1\n",
    "\n",
    "    src_nodes.append(src)\n",
    "    dst_nodes.append(dst)\n",
    "    edge_types.append(relation_to_id[rel])\n",
    "\n",
    "edge_index = torch.tensor([src_nodes, dst_nodes], dtype=torch.long)\n",
    "edge_type = torch.tensor(edge_types, dtype=torch.long)\n",
    "\n",
    "print(f\"âœ… Total unique edge types: {len(relation_to_id)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8783d5b7-bd87-4232-b4fe-e35dc2723990",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build PyG graph object\n",
    "# -----------------------------\n",
    "data = Data(x=x, edge_index=edge_index, edge_type=edge_type)\n",
    "\n",
    "# -----------------------------\n",
    "# Split for link prediction\n",
    "# -----------------------------\n",
    "ei = data.edge_index.numpy()\n",
    "et = data.edge_type.numpy()\n",
    "\n",
    "ei_train, ei_test, et_train, et_test = train_test_split(ei.T, et, test_size=0.2, random_state=42)\n",
    "ei_train, ei_val, et_train, et_val = train_test_split(ei_train, et_train, test_size=0.1, random_state=42)\n",
    "\n",
    "ei_train = torch.tensor(ei_train, dtype=torch.long).t()\n",
    "ei_val = torch.tensor(ei_val, dtype=torch.long).t()\n",
    "ei_test = torch.tensor(ei_test, dtype=torch.long).t()\n",
    "\n",
    "et_train = torch.tensor(et_train, dtype=torch.long)\n",
    "et_val = torch.tensor(et_val, dtype=torch.long)\n",
    "et_test = torch.tensor(et_test, dtype=torch.long)\n",
    "\n",
    "# Generate negative samples\n",
    "neg_train = negative_sampling(ei_train, num_nodes=data.num_nodes)\n",
    "neg_val = negative_sampling(ei_val, num_nodes=data.num_nodes)\n",
    "neg_test = negative_sampling(ei_test, num_nodes=data.num_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "889d9ab6-1810-4078-97c1-79dfcb8ed16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RGCN Model\n",
    "# -----------------------------\n",
    "class RGCNLinkPredictor(torch.nn.Module):\n",
    "    def __init__(self, in_dim, hidden_dim, out_dim, num_relations):\n",
    "        super().__init__()\n",
    "        self.conv1 = RGCNConv(in_dim, hidden_dim, num_relations)\n",
    "        self.conv2 = RGCNConv(hidden_dim, out_dim, num_relations)\n",
    "\n",
    "    def encode(self, x, edge_index, edge_type):\n",
    "        x = F.relu(self.conv1(x, edge_index, edge_type))\n",
    "        return self.conv2(x, edge_index, edge_type)\n",
    "\n",
    "    def decode(self, z, edge_index):\n",
    "        return (z[edge_index[0]] * z[edge_index[1]]).sum(dim=-1)\n",
    "\n",
    "model = RGCNLinkPredictor(data.num_features, hidden_dim=64, out_dim=32, num_relations=len(relation_to_id))\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "89cd8130-d5c9-481f-aea8-30a7f35b4356",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training function\n",
    "# -----------------------------\n",
    "def train():\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    z = model.encode(data.x, ei_train, et_train)\n",
    "    pos_score = model.decode(z, ei_train)\n",
    "    neg_score = model.decode(z, neg_train)\n",
    "\n",
    "    pos_labels = torch.ones_like(pos_score)\n",
    "    neg_labels = torch.zeros_like(neg_score)\n",
    "\n",
    "    loss = F.binary_cross_entropy_with_logits(pos_score, pos_labels) + \\\n",
    "           F.binary_cross_entropy_with_logits(neg_score, neg_labels)\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "25601585-a917-4f08-b318-cd63292226cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation function\n",
    "# -----------------------------\n",
    "def evaluate(ei_pos, et_pos, ei_neg):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        z = model.encode(data.x, ei_pos, et_pos)\n",
    "        pos_score = model.decode(z, ei_pos).sigmoid().cpu().numpy()\n",
    "        neg_score = model.decode(z, ei_neg).sigmoid().cpu().numpy()\n",
    "\n",
    "        y_true = np.concatenate([np.ones_like(pos_score), np.zeros_like(neg_score)])\n",
    "        y_score = np.concatenate([pos_score, neg_score])\n",
    "\n",
    "        roc = roc_auc_score(y_true, y_score)\n",
    "        pr = average_precision_score(y_true, y_score)\n",
    "\n",
    "        return roc, pr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2a339c90-8506-4c8b-bb50-ddad12c63c07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 010 | Loss: 1.3706 | Val ROC-AUC: 0.3899 | PR-AUC: 0.4716\n",
      "Epoch 020 | Loss: 1.3162 | Val ROC-AUC: 0.5627 | PR-AUC: 0.6363\n",
      "Epoch 030 | Loss: 1.2565 | Val ROC-AUC: 0.6912 | PR-AUC: 0.7718\n",
      "Epoch 040 | Loss: 1.2081 | Val ROC-AUC: 0.7733 | PR-AUC: 0.8301\n",
      "Epoch 050 | Loss: 1.1452 | Val ROC-AUC: 0.8014 | PR-AUC: 0.8543\n",
      "Epoch 060 | Loss: 1.0669 | Val ROC-AUC: 0.7763 | PR-AUC: 0.8381\n",
      "Epoch 070 | Loss: 1.0382 | Val ROC-AUC: 0.7549 | PR-AUC: 0.8243\n",
      "Epoch 080 | Loss: 1.0076 | Val ROC-AUC: 0.7369 | PR-AUC: 0.8148\n",
      "Epoch 090 | Loss: 0.9768 | Val ROC-AUC: 0.7449 | PR-AUC: 0.8212\n",
      "Epoch 100 | Loss: 0.9526 | Val ROC-AUC: 0.7481 | PR-AUC: 0.8224\n",
      "Epoch 110 | Loss: 0.9301 | Val ROC-AUC: 0.7553 | PR-AUC: 0.8255\n",
      "Epoch 120 | Loss: 0.9160 | Val ROC-AUC: 0.7473 | PR-AUC: 0.8185\n",
      "Epoch 130 | Loss: 0.9056 | Val ROC-AUC: 0.7423 | PR-AUC: 0.8151\n",
      "Epoch 140 | Loss: 0.8958 | Val ROC-AUC: 0.7446 | PR-AUC: 0.8164\n",
      "Epoch 150 | Loss: 0.8860 | Val ROC-AUC: 0.7464 | PR-AUC: 0.8174\n",
      "Epoch 160 | Loss: 0.8744 | Val ROC-AUC: 0.7416 | PR-AUC: 0.8142\n",
      "Epoch 170 | Loss: 0.8640 | Val ROC-AUC: 0.7376 | PR-AUC: 0.8126\n",
      "Epoch 180 | Loss: 0.8548 | Val ROC-AUC: 0.7421 | PR-AUC: 0.8158\n",
      "Epoch 190 | Loss: 0.8467 | Val ROC-AUC: 0.7417 | PR-AUC: 0.8151\n",
      "Epoch 200 | Loss: 0.8398 | Val ROC-AUC: 0.7389 | PR-AUC: 0.8125\n",
      "\n",
      "ðŸ§ª Test ROC-AUC: 0.8506 | Test PR-AUC: 0.8788\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "# -----------------------------\n",
    "for epoch in range(1, 201):\n",
    "    loss = train()\n",
    "    if epoch % 10 == 0:\n",
    "        roc, pr = evaluate(ei_val, et_val, neg_val)\n",
    "        print(f\"Epoch {epoch:03d} | Loss: {loss:.4f} | Val ROC-AUC: {roc:.4f} | PR-AUC: {pr:.4f}\")\n",
    "\n",
    "# Final test evaluation\n",
    "roc, pr = evaluate(ei_test, et_test, neg_test)\n",
    "print(f\"\\nðŸ§ª Test ROC-AUC: {roc:.4f} | Test PR-AUC: {pr:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "02682b24-0c5d-4c74-af08-166707796a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "torch.save(model.state_dict(), \"protbert_rgcn_link_predictor_modes_148k.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "391cbd46-2ee9-421a-8f7d-c96e76fe843c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
